{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sonali/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "TensorFlow version: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow eager execution: True\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[2.0, 4.0],[3.0,5.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=tf.matmul(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16. 28.]\n",
      " [21. 37.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant([[1, 2],[3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=tf.add(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.multiply(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tfe.Variable([[1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=31, shape=(1, 1), dtype=float32, numpy=array([[2.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "with tfe.GradientTape() as tape:\n",
    "    loss=w*w\n",
    "grad=tape.gradient(loss,[w])\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES=1000\n",
    "training_inputs=tf.random_normal([NUM_EXAMPLES])\n",
    "noise=tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs=training_inputs*3+2+noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(input, weight, bias):\n",
    "    return input*weight+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights, biases):\n",
    "    error=prediction(training_inputs, weights, biases)-training_outputs\n",
    "    return tf.reduce_mean(tf.square(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(weights, biases):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_value=loss(weights, biases)\n",
    "    return tape.gradient(loss_value, [weights, biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 71.216\n"
     ]
    }
   ],
   "source": [
    "train_steps=200\n",
    "learning_rate=0.01\n",
    "W=tfe.Variable(5.)\n",
    "B=tfe.Variable(10.)\n",
    "print(\"initial loss: {:.3f}\".format(loss(W,B)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 000 is 68.373\n",
      "loss at step 020 is 30.496\n",
      "loss at step 040 is 13.939\n",
      "loss at step 060 is 6.694\n",
      "loss at step 080 is 3.521\n",
      "loss at step 100 is 2.129\n",
      "loss at step 120 is 1.519\n",
      "loss at step 140 is 1.250\n",
      "loss at step 160 is 1.132\n",
      "loss at step 180 is 1.080\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_steps):\n",
    "    dW, dB=grad(W,B)\n",
    "    W.assign_sub(dW*learning_rate)\n",
    "    B.assign_sub(dB*learning_rate)\n",
    "    if(i%20==0):\n",
    "        print(\"loss at step {:03d} is {:.3f}\".format(i,loss(W,B)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss: 1.058\n"
     ]
    }
   ],
   "source": [
    "print(\"final loss: {:.3f}\".format(loss(W,B)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= 2.99216222763, B=2.09937644005\n"
     ]
    }
   ],
   "source": [
    "print(\"W= {}, B={}\".format(W.numpy(), B.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad=tfe.gradients_function(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7382, shape=(), dtype=float32, numpy=9.0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7389, shape=(), dtype=float32, numpy=7.8>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(3.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradgrad=tfe.gradients_function(lambda x: grad(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7402, shape=(), dtype=int32, numpy=2>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradgrad(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad3=tfe.gradients_function(lambda x: gradgrad(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad3(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs(x):\n",
    "    return x if x>0 else -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad=tfe.gradients_function(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=6, shape=(), dtype=int32, numpy=1>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7428, shape=(), dtype=int32, numpy=-1>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7437, shape=(), dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log1exp(x):\n",
    "    return tf.log(1+tf.exp(x))\n",
    "grad_log1exp=tfe.gradients_function(log1exp)\n",
    "grad_log1exp(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7446, shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log1exp(100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def log1exp(x):\n",
    "    e=tf.exp(x)\n",
    "    def grad(dy):\n",
    "        return dy*(1-1/(1+e))\n",
    "    return tf.log(1+e),grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_logexp=tfe.gradients_function(log1exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7456, shape=(), dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_logexp(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=7467, shape=(), dtype=float32, numpy=1.0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_logexp(1000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([tf.keras.layers.Dense(10, input_shape=(784,)), tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel,self).__init__()\n",
    "        self.dense1=tf.keras.layers.Dense(units=10)\n",
    "        self.dense2=tf.keras.layers.Dense(units=10)\n",
    "    def call(self, input):\n",
    "        result=self.dense1(input)\n",
    "        result=self.dense2(result)\n",
    "        result=self.dense2(result)\n",
    "        return result\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=tf.zeros([1,1,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 784)\n"
     ]
    }
   ],
   "source": [
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset.train('./datasets').shuffle(60000).repeat(4).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    prediction=model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_value=loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y=tfe.Iterator(dataset_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.253\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial loss: {:.3f}\".format(loss(model, x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step :0000 is 1.861\n",
      "loss at step :0200 is 1.283\n",
      "loss at step :0400 is 1.367\n",
      "loss at step :0600 is 1.278\n",
      "loss at step :0800 is 1.054\n",
      "loss at step :1000 is 1.270\n",
      "loss at step :1200 is 0.983\n",
      "loss at step :1400 is 0.965\n",
      "loss at step :1600 is 0.875\n",
      "loss at step :1800 is 1.020\n",
      "loss at step :2000 is 0.608\n",
      "loss at step :2200 is 0.742\n",
      "loss at step :2400 is 0.832\n",
      "loss at step :2600 is 0.757\n",
      "loss at step :2800 is 0.860\n",
      "loss at step :3000 is 0.738\n",
      "loss at step :3200 is 1.020\n",
      "loss at step :3400 is 0.382\n",
      "loss at step :3600 is 0.554\n",
      "loss at step :3800 is 0.628\n",
      "loss at step :4000 is 0.527\n",
      "loss at step :4200 is 0.580\n",
      "loss at step :4400 is 0.470\n",
      "loss at step :4600 is 0.489\n",
      "loss at step :4800 is 0.591\n",
      "loss at step :5000 is 0.440\n",
      "loss at step :5200 is 0.426\n",
      "loss at step :5400 is 0.432\n",
      "loss at step :5600 is 0.573\n",
      "loss at step :5800 is 0.515\n",
      "loss at step :6000 is 0.749\n",
      "loss at step :6200 is 0.446\n",
      "loss at step :6400 is 0.429\n",
      "loss at step :6600 is 0.492\n",
      "loss at step :6800 is 0.772\n",
      "loss at step :7000 is 0.484\n",
      "loss at step :7200 is 0.507\n",
      "loss at step :7400 is 0.756\n"
     ]
    }
   ],
   "source": [
    "for (i,(x,y)) in enumerate(tfe.Iterator(dataset_train)):\n",
    "    grads=grad(model, x,y)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables),global_step=tf.train.get_or_create_global_step())\n",
    "    if i%200==0:\n",
    "        print(\"loss at step :{:04d} is {:.3f}\".format(i, loss(model, x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss: 0.226\n"
     ]
    }
   ],
   "source": [
    "print(\"final loss: {:.3f}\".format(loss(model,x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.W=tfe.Variable(5., name=\"weight\")\n",
    "        self.B=tfe.Variable(10., name=\"bias\")\n",
    "    def predict(self, inputs):\n",
    "        return inputs*self.W+self.B\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES=2000\n",
    "training_examples=tf.random_normal([NUM_EXAMPLES])\n",
    "noise=tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs=training_examples*3+2+noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, targets):\n",
    "    error=model.predict(inputs)-targets\n",
    "    return tf.reduce_mean(tf.square(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        loss_val=loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_val,[model.W,model.B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 69.093\n"
     ]
    }
   ],
   "source": [
    "model=Model()\n",
    "writer=tf.contrib.summary.create_file_writer(\"./\")\n",
    "writer.set_as_default()\n",
    "global_step=tf.train.get_or_create_global_step()\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "print(\"initial loss: {:.3f}\".format(loss(model,training_examples, training_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at STEP : 000 is 66.383\n",
      "loss at STEP : 020 is 30.018\n",
      "loss at STEP : 040 is 13.880\n",
      "loss at STEP : 060 is 6.717\n",
      "loss at STEP : 080 is 3.539\n",
      "loss at STEP : 100 is 2.128\n",
      "loss at STEP : 120 is 1.502\n",
      "loss at STEP : 140 is 1.224\n",
      "loss at STEP : 160 is 1.101\n",
      "loss at STEP : 180 is 1.046\n",
      "loss at STEP : 200 is 1.022\n",
      "loss at STEP : 220 is 1.011\n",
      "loss at STEP : 240 is 1.006\n",
      "loss at STEP : 260 is 1.004\n",
      "loss at STEP : 280 is 1.003\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    grads=grad(model, training_examples, training_outputs)\n",
    "    global_step.assign_add(1)\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(100):\n",
    "        optimizer.apply_gradients(zip(grads, [model.W,model.B]), global_step=global_step)\n",
    "        if i%20==0:\n",
    "            print(\"loss at STEP : {:03d} is {:.3f}\".format(i, loss(model, training_examples, training_outputs)))\n",
    "        tf.contrib.summary.scalar('loss',loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss: 1.003 \n"
     ]
    }
   ],
   "source": [
    "print(\"final loss: {:.3f} \".format(loss(model, training_examples, training_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final W: 2.992 and final B: 2.099\n"
     ]
    }
   ],
   "source": [
    "print(\"final W: {:.3f} and final B: {:.3f}\".format(W.numpy(),B.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>\n"
     ]
    }
   ],
   "source": [
    "x=tfe.Variable(2.)\n",
    "checkpoint=tfe.Checkpoint(x=x)\n",
    "x.assign(10.)\n",
    "save_path=checkpoint.save(\"./chpt/\")\n",
    "x.assign(5.)\n",
    "checkpoint.restore(save_path)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=751958, shape=(), dtype=float64, numpy=7.333333333333333>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=tfe.metrics.Mean(\"loss\")\n",
    "m(5.)\n",
    "m.result()\n",
    "m([8,9])\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
